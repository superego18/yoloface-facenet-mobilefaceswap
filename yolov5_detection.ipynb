{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1YPE3XWV4yYRnT6dQpUSxtDxHL28N1nii","authorship_tag":"ABX9TyMl9QLPaKtaTJu69RiQGDlO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QQ6kREefe460","executionInfo":{"status":"ok","timestamp":1682408342875,"user_tz":-540,"elapsed":3,"user":{"displayName":"조민정","userId":"09227422768951763410"}},"outputId":"72c6b91b-8101-4b2d-db90-c3a6e31d667a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/yoloface\n"]}],"source":["%cd /content/drive/MyDrive/yoloface"]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7RovUwp7icjK","executionInfo":{"status":"ok","timestamp":1682408359378,"user_tz":-540,"elapsed":11896,"user":{"displayName":"조민정","userId":"09227422768951763410"}},"outputId":"eab78776-5685-4646-b182-56264847a09f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: joblib==1.2.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (1.2.0)\n","Collecting matplotlib==3.5.1\n","  Downloading matplotlib-3.5.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy==1.22.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (1.22.4)\n","Collecting onnx==1.12.0\n","  Downloading onnx-1.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opencv_python==4.6.0.66\n","  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pandas==1.4.2\n","  Downloading pandas-1.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting Pillow==9.3.0\n","  Downloading Pillow-9.3.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (6.0)\n","Requirement already satisfied: requests==2.27.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (2.27.1)\n","Collecting scipy==1.7.3\n","  Downloading scipy-1.7.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.8/39.8 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting seaborn==0.11.2\n","  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting setuptools==61.2.0\n","  Downloading setuptools-61.2.0-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting thop==0.1.1.post2207130030\n","  Downloading thop-0.1.1.post2207130030-py3-none-any.whl (15 kB)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.12.1+cu116 (from versions: 1.7.1, 1.8.0, 1.8.1, 1.9.0, 1.9.1, 1.10.0, 1.10.1, 1.10.2, 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.12.1+cu116\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install face_detector"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hVO5BfdJid9J","executionInfo":{"status":"ok","timestamp":1682408383677,"user_tz":-540,"elapsed":24305,"user":{"displayName":"조민정","userId":"09227422768951763410"}},"outputId":"3e733e0a-9f99-4767-8641-2cff8eddd541"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting face_detector\n","  Downloading face_detector-0.4-py3-none-any.whl (9.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gast==0.2.2\n","  Downloading gast-0.2.2.tar.gz (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting dlib==19.17.0\n","  Downloading dlib-19.17.0.tar.gz (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tensorboard==1.13.1\n","  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting Keras-Applications==1.0.7\n","  Downloading Keras_Applications-1.0.7-py2.py3-none-any.whl (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mock==2.0.0\n","  Downloading mock-2.0.0-py2.py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting Keras-Preprocessing==1.0.9\n","  Downloading Keras_Preprocessing-1.0.9-py2.py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting astor==0.7.1\n","  Downloading astor-0.7.1-py2.py3-none-any.whl (27 kB)\n","Collecting termcolor==1.1.0\n","  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting protobuf==3.7.1\n","  Downloading protobuf-3.7.1-py2.py3-none-any.whl (404 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.6/404.6 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting grpcio==1.19.0\n","  Downloading grpcio-1.19.0.tar.gz (14.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting Markdown==3.1\n","  Downloading Markdown-3.1-py2.py3-none-any.whl (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pbr==5.1.3\n","  Downloading pbr-5.1.3-py2.py3-none-any.whl (107 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting face_detector\n","  Downloading face_detector-0.3-py3-none-any.whl (9.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading face_detector-0.2.9-py3-none-any.whl (9.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading face_detector-0.2.8-py3-none-any.whl (9.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading face_detector-0.2.7-py3-none-any.whl (9.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading face_detector-0.2.6-py3-none-any.whl (9.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading face_detector-0.2.5-py3-none-any.whl (9.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading face_detector-0.2.4-py3-none-any.whl (9.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading face_detector-0.2.3-py3-none-any.whl (9.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading face_detector-0.2.2-py3-none-any.whl (9.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading face_detector-0.2.1-py3-none-any.whl (13 kB)\n","  Downloading face_detector-0.2-py3-none-any.whl (13 kB)\n","Installing collected packages: face_detector\n","Successfully installed face_detector-0.2\n"]}]},{"cell_type":"code","source":["!pip install thop"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yAkdmmIaif1N","executionInfo":{"status":"ok","timestamp":1682408388720,"user_tz":-540,"elapsed":5050,"user":{"displayName":"조민정","userId":"09227422768951763410"}},"outputId":"5b64d620-b8b7-4ca5-ce66-913aa5016292"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from thop) (2.0.0+cu118)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->thop) (3.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->thop) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->thop) (1.11.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->thop) (3.11.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->thop) (2.0.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->thop) (3.1.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->thop) (16.0.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->thop) (3.25.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->thop) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->thop) (1.3.0)\n","Installing collected packages: thop\n","Successfully installed thop-0.1.1.post2209072238\n"]}]},{"cell_type":"code","source":["!pip install facenet_pytorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dtwwodZviiJ-","executionInfo":{"status":"ok","timestamp":1682408392906,"user_tz":-540,"elapsed":4193,"user":{"displayName":"조민정","userId":"09227422768951763410"}},"outputId":"2610b566-498c-4f5d-b905-bf5ef17674aa"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting facenet_pytorch\n","  Downloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from facenet_pytorch) (1.22.4)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from facenet_pytorch) (8.4.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from facenet_pytorch) (0.15.1+cu118)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from facenet_pytorch) (2.27.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->facenet_pytorch) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->facenet_pytorch) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->facenet_pytorch) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->facenet_pytorch) (1.26.15)\n","Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->facenet_pytorch) (2.0.0+cu118)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision->facenet_pytorch) (2.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision->facenet_pytorch) (3.11.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision->facenet_pytorch) (3.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision->facenet_pytorch) (4.5.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision->facenet_pytorch) (3.1.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchvision->facenet_pytorch) (1.11.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision->facenet_pytorch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision->facenet_pytorch) (16.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.0.0->torchvision->facenet_pytorch) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.0.0->torchvision->facenet_pytorch) (1.3.0)\n","Installing collected packages: facenet_pytorch\n","Successfully installed facenet_pytorch-2.5.3\n"]}]},{"cell_type":"code","source":["!pip install face_recognition"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eaOD2L2yij9p","executionInfo":{"status":"ok","timestamp":1682408422938,"user_tz":-540,"elapsed":30036,"user":{"displayName":"조민정","userId":"09227422768951763410"}},"outputId":"976d795e-61db-4bd6-98a4-76885e6a32a5"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting face_recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.9/dist-packages (from face_recognition) (8.1.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from face_recognition) (8.4.0)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.9/dist-packages (from face_recognition) (19.24.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from face_recognition) (1.22.4)\n","Collecting face-recognition-models>=0.3.0\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566185 sha256=d49f00fff021c6c8d130699500cf0edf6c33d0f3753f9f0e4a27e8f8b0560e65\n","  Stored in directory: /root/.cache/pip/wheels/22/a8/60/4a2aeb763d63f50190f4c4e07069a22245347eeafdb3a67551\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face_recognition\n","Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"]}]},{"cell_type":"code","source":["from face_detector import *\n","import numpy as np\n","from PIL import Image\n","from facenet_pytorch import MTCNN, InceptionResnetV1\n","import torch \n","import numpy as np\n"],"metadata":{"id":"dAMLI-rEimTG","executionInfo":{"status":"ok","timestamp":1682408445008,"user_tz":-540,"elapsed":22087,"user":{"displayName":"조민정","userId":"09227422768951763410"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import io\n","import face_recognition"],"metadata":{"id":"y9URLUtim-rs","executionInfo":{"status":"ok","timestamp":1682408521992,"user_tz":-540,"elapsed":3046,"user":{"displayName":"조민정","userId":"09227422768951763410"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["target_path = \"/content/drive/MyDrive/yoloface/test/\"\n","\n","files = os.listdir(target_path) # 해당 폴더에 있는 파일 이름을 리스트 형태로 받음\n","files"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PiPLEpsQiobw","executionInfo":{"status":"ok","timestamp":1682408643394,"user_tz":-540,"elapsed":1521,"user":{"displayName":"조민정","userId":"09227422768951763410"}},"outputId":"95892aed-85bb-4c75-945d-5f7995bcdd49"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['test2.jpeg',\n"," 'test3.jpeg',\n"," 'test4.jpeg',\n"," 'test5.jpeg',\n"," 'test6.jpeg',\n"," 'test7.jpeg',\n"," 'test8.jpeg',\n"," 'test10.jpeg',\n"," 'test11.JPG',\n"," 'result1',\n"," 'result2',\n"," 'result3',\n"," 'result4',\n"," 'result5',\n"," 'result6',\n"," 'result7',\n"," 'result8',\n"," 'result9']"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["def get_face_embedding(face):\n","  #image = Image.open(face)\n","  numpy_image = np.array(face)\n","  \n","  return face_recognition.face_encodings(numpy_image)\n","\n"],"metadata":{"id":"n4u28B8Tmu6p","executionInfo":{"status":"ok","timestamp":1682408646496,"user_tz":-540,"elapsed":1,"user":{"displayName":"조민정","userId":"09227422768951763410"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["file_list = os.listdir('/content/drive/MyDrive/pytorch_face_recognition/photos/charmzu')\n","chanzu_embedding_dict = {}\n","    \n","for file in file_list:\n","    file_name = file.split('.')[0]\n","    image = Image.open('/content/drive/MyDrive/pytorch_face_recognition/photos/charmzu/' + file)\n","    embedding = get_face_embedding(image)\n","    if len(embedding) > 0:  # 얼굴영역 face가 제대로 detect되지 않으면  len(embedding)==0인 경우가 발생하므로\n","        chanzu_embedding_dict[file_name] = embedding[0]"],"metadata":{"id":"mlh_VZRUmrWD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def yolo_detection(img, save_path=None):\n","  model = YoloDetector(target_size = 736,device = \"cuda:0\",min_face = 20)\n","  bboxes_list= {}\n","  faces_list = []\n","  \n","  embedding_dict = {}\n","  #img_faces = []\n","  image = Image.open(img) #이미지 열기\n","  orgimg = np.array(Image.open(img)) #이미지 배열값으로 변환\n","  bboxes, point = model.predict(orgimg) #bbox, point \n","\n","  count = 0\n","  #detecting 한 얼굴 bbox 배열 \n","  for bbox in bboxes[0]:\n","    count+=1\n","    face = image.crop(bbox)#이미지에서 얼굴 사진만 크롭하기\n","    face_path = f'/content/drive/MyDrive/yoloface/results/target_4.jpg'\n","    face.save(face_path,'jpeg') #크롭한 얼굴 이미지 저장 \n","    face_embedding = get_face_embedding(face) #얼굴 임베딩 벡터 반환 \n","    if len(face_embedding) > 0:  # 얼굴영역 face가 제대로 detect되지 않으면  len(embedding)==0인 경우가 발생하므로\n","        embedding_dict[f'{count}'] = face_embedding\n","        bboxes_list[f'{count}'] = bbox\n","\n","    faces_list.append(face)\n","  \n","    #face.save(f'/content/drive/MyDrive/yoloface/test/result/{count}.jpeg','jpeg') #크롭한 얼굴 이미지 저장 \n","\n","  #bboxes_list.append(bboxes[0]) #bbox 경계 좌표값 저장 \n","  #faces_list.append(faces_list)\n","\n","  return embedding_dict,bboxes_list"],"metadata":{"id":"jfr5p9W0opEE","executionInfo":{"status":"ok","timestamp":1682409544317,"user_tz":-540,"elapsed":4,"user":{"displayName":"조민정","userId":"09227422768951763410"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8tQQf3EsWNPM","executionInfo":{"status":"ok","timestamp":1682408342875,"user_tz":-540,"elapsed":45774,"user":{"displayName":"조민정","userId":"09227422768951763410"}},"outputId":"2f010ce0-5bc7-4f8e-84ff-2a731d1cb3ae"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["embedding_dict ,bboxes_list = yolo_detection('/content/drive/MyDrive/yoloface/test/test12.JPG')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j4ltYCi-orzk","executionInfo":{"status":"ok","timestamp":1682409555178,"user_tz":-540,"elapsed":14,"user":{"displayName":"조민정","userId":"09227422768951763410"}},"outputId":"eee5fdcd-4144-4c3f-d915-6497883c988c"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n","/content/drive/MyDrive/yoloface/weights/yolov5n_state_dict.pt\n"]}]},{"cell_type":"code","source":["embedding_dict.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ak1wHd2lrpRC","executionInfo":{"status":"ok","timestamp":1682250348634,"user_tz":-540,"elapsed":396,"user":{"displayName":"조민정","userId":"09227422768951763410"}},"outputId":"5ad2de34-5810-4352-9423-3c54615fffbe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['1', '2', '3', '4', '6'])"]},"metadata":{},"execution_count":108}]},{"cell_type":"code","source":["def get_distance(name1, name2):\n","    return np.linalg.norm(chanzu_embedding_dict[name1]-embedding_dict[name2], ord=2)\n","\n","# name1과 name2의 거리를 비교하는 함수를 생성하되, name1은 미리 지정하고, name2는 호출시에 인자로 받도록 합니다.\n","def get_sort_key_func(name1):\n","    def get_distance_from_name1(name2):\n","        #print(len(embedding_dict[name2]))\n","        #print('name',name2)\n","        return get_distance(name1, name2)\n","    return get_distance_from_name1\n","\n","def get_nearest_face(name, top=5):\n","    sort_key_func = get_sort_key_func(name)\n","    sorted_faces = sorted(embedding_dict.items(), key=lambda x:sort_key_func(x[0]))\n","    return sorted_faces\n","\n","    # for i in range(top+1):\n","    #     #if i == 0: continue\n","    #     if sorted_faces[i]:\n","    #         print(f'순위 {i} : 이름({sorted_faces[i][0]}), 거리({sort_key_func(sorted_faces[i][0])})')\n","     "],"metadata":{"id":"pqFf5hDBiqg0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sorted_faces = get_nearest_face('4')\n"],"metadata":{"id":"QxglTPYytK-H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["face_detection = {}\n","count = 0\n","for i in range(len(sorted_faces)):\n","  print(sorted_faces[i][0])\n","  if i == 0:\n","    target = sorted_faces[0][0]\n","    face_detection['target'] = bboxes_list[target]\n","  else :\n","    count+=1\n","    face_detection[f'unknown{count}'] = bboxes_list[sorted_faces[i][0]]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wyZ31g7jt8Lq","executionInfo":{"status":"ok","timestamp":1682250365844,"user_tz":-540,"elapsed":8,"user":{"displayName":"조민정","userId":"09227422768951763410"}},"outputId":"fb48fa6c-9cbc-4249-d79c-ed8238de995c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","3\n","2\n","6\n","1\n"]}]},{"cell_type":"code","source":["face_detection"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QWPot-iLxrkS","executionInfo":{"status":"ok","timestamp":1682250369074,"user_tz":-540,"elapsed":598,"user":{"displayName":"조민정","userId":"09227422768951763410"}},"outputId":"063f05bd-cf1b-4a11-c8a0-72bc7de6886d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'target': [1179, 574, 1266, 668],\n"," 'unknown1': [818, 583, 880, 653],\n"," 'unknown2': [949, 568, 1013, 644],\n"," 'unknown3': [426, 634, 488, 701],\n"," 'unknown4': [545, 615, 600, 685]}"]},"metadata":{},"execution_count":112}]},{"cell_type":"code","source":["def DrawRectImg(img, face_detection):\n","    orgimg = np.array(Image.open(img))\n","    target_color = (0, 0, 255) # BGR\n","    target_thickness = 2 # 이미지 사이즈에 맞게 조절해야할지도\n","    unknown_color = (0, 255, 0) # BGR\n","    unknown_thickness = 2 # 이미지 사이즈에 맞게 조절해야할지도\n","    font_scale = 1 # 위와 동일\n","\n","    \n","    \n","    for face_id, bbox in face_detection.items():\n","          # bbox: x0, y0, x1, y1\n","          if face_id == 'target':\n","            bbox = np.round(bbox).astype(int)\n","            cv2.rectangle(orgimg, (bbox[0], bbox[1]), (bbox[2], bbox[3]),target_color, target_thickness)\n","            cv2.putText(orgimg, face_id, (bbox[0], bbox[1]-5),1, font_scale, target_thickness, target_thickness)\n","          else:\n","            bbox = np.round(bbox).astype(int)\n","            cv2.rectangle(orgimg, (bbox[0], bbox[1]), (bbox[2], bbox[3]),unknown_color, target_thickness)\n","            cv2.putText(orgimg, face_id, (bbox[0], bbox[1]-5),1, font_scale, unknown_color, target_thickness)\n","    img_draw = cv2.cvtColor(orgimg,cv2.COLOR_BGR2RGB)\n","\n","    return img_draw"],"metadata":{"id":"cASk_Ir9vWud"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#'/content/drive/MyDrive/yoloface/test/test3.jpeg'\n","from google.colab.patches import cv2_imshow\n","img = DrawRectImg('/content/drive/MyDrive/yoloface/test/test3.jpeg', face_detection)\n","cv2_imshow(img)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":870,"output_embedded_package_id":"1sJH5YYXntm4JiauZg8r8HWvs7DLyNXZA"},"id":"Lo7LQCPHyipB","executionInfo":{"status":"ok","timestamp":1682250384321,"user_tz":-540,"elapsed":9432,"user":{"displayName":"조민정","userId":"09227422768951763410"}},"outputId":"f2f09876-5f3e-4fd4-ede9-aed4f15845d2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["## 다른 사진으로 test"],"metadata":{"id":"rK_ue7SW4YIn"}},{"cell_type":"code","source":["embedding_dict,bboxes_list = yolo_detection('/content/drive/MyDrive/yoloface/test/test2.jpeg')\n","\n","sorted_faces = get_nearest_face('4')\n","face_detection = {}\n","count = 0\n","for i in range(len(sorted_faces)):\n","  print(sorted_faces[i][0])\n","  if i == 0:\n","    target = sorted_faces[0][0]\n","    face_detection['target'] = bboxes_list[target]\n","  else :\n","    count+=1\n","    face_detection[f'unknown{count}'] = bboxes_list[sorted_faces[i][0]]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdMcgpO88D48","executionInfo":{"status":"ok","timestamp":1682252247920,"user_tz":-540,"elapsed":599,"user":{"displayName":"조민정","userId":"09227422768951763410"}},"outputId":"3e6cb301-c1d5-4f3d-85b3-0f1b92cadf1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n","/content/drive/MyDrive/yoloface/weights/yolov5n_state_dict.pt\n","WARNING: --img-size 981 must be multiple of max stride 32, updating to 992\n","2\n","6\n","4\n","1\n","3\n"]}]},{"cell_type":"code","source":["img = DrawRectImg('/content/drive/MyDrive/yoloface/test/test2.jpeg', face_detection)\n","cv2_imshow(img)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":870,"output_embedded_package_id":"1C-6HY3bxLpjjMBi4-BkG8hv_313NcpS4"},"id":"Zp8O_jc3Czus","executionInfo":{"status":"ok","timestamp":1682252275202,"user_tz":-540,"elapsed":6681,"user":{"displayName":"조민정","userId":"09227422768951763410"}},"outputId":"6abfa2bd-1307-4d7c-9142-1d966035899a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"Z-8aVqOSDH9m"},"execution_count":null,"outputs":[]}]}